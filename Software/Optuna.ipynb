{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importazione librerie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:25:01.405757500Z",
     "start_time": "2023-09-11T09:24:51.229089600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes: (1367, 224, 224) (1367,)\n",
      "Test set shapes: (152, 224, 224) (152,)\n"
     ]
    }
   ],
   "source": [
    "# Directory containing images\n",
    "whistleImagesDirectory = 'Data\\\\Sobel\\\\Whistle'\n",
    "noiseImagesDirectory = 'Data\\\\Sobel\\\\Noise'\n",
    "\n",
    "# List all image files in the directory\n",
    "whistleFiles = os.listdir(whistleImagesDirectory)\n",
    "noiseFiles = os.listdir(noiseImagesDirectory)\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load and preprocess whistle images\n",
    "for image_file in whistleFiles:\n",
    "    image_path = os.path.join(whistleImagesDirectory, image_file)\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = image.resize((224, 224))  # Resize\n",
    "    image = np.array(image)  # Convert to NumPy array\n",
    "    images.append(image)\n",
    "    labels.append(1)    #etichetta delfino\n",
    "\n",
    "\n",
    "# Load and preprocess noise images\n",
    "for image_file in noiseFiles:\n",
    "    image_path = os.path.join(noiseImagesDirectory, image_file)\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image)  # Convert to NumPy array\n",
    "    images.append(image)\n",
    "    labels.append(0)    #etichetta rumore\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(images)/255.0\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split the dataset into training and test sets                 (90/10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_val, y_val = [], []\n",
    "\n",
    "# Split the dataset into training, validation, and test sets    (70/20/10)\n",
    "#X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Train set shapes:\", X_train.shape, y_train.shape)\n",
    "#print(\"Validation set shapes:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T09:25:09.291900400Z",
     "start_time": "2023-09-11T09:25:01.413759800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optuna\n",
    "Utilizzo di Optuna per la scelta dell’architettura della rete neurale, ovvero un framework per l'ottimizzazione degli iperparametri. Sceglie automaticamente gli iperparametri di un modello e lo allena, poi valuta la rete migliore basandosi sul registro storico dei tentativi. Il numero di tentativi (_trial_) minimo consigliato è 50, ma per casi più importanti può essere impostato anche a centinaia.\n",
    "In questo modo, viene generata una rete che ha da 3 a 5 Conv2D layers, ognuno con funzione di attivazione relu, kernel size (3,3), numero di filtri uno tra [16, 32, 64, 128, 256, 512], seguito da un MaxPooling2D.\n",
    "Viene utilizzato un flatten e infine vengono inseriti uno o due Dense layer con un numero di neuroni tra [64, 128, 256, 512, 1024], più un Dense layer finale.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    input = Input(shape=(224, 224, 1))\n",
    "\n",
    "    # Crea layer convoluzionali\n",
    "    x = input\n",
    "    for i in range(trial.suggest_int(\"n_layers\", 3, 5)):\n",
    "        filters=trial.suggest_categorical(f\"filters_{i}\", [16, 32, 64, 128, 256, 512])\n",
    "        x = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=\"relu\"\n",
    "        )(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        print(filters)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Crea dense layers\n",
    "    for i in range(trial.suggest_int(\"n_dense_layers\", 1, 2)):\n",
    "        units = trial.suggest_categorical(f\"dense_units_{i}\", [64, 128, 256, 512, 1024])\n",
    "        x = Dense(\n",
    "            units=units,\n",
    "            activation=\"relu\"\n",
    "        )(x)\n",
    "        print('Dense', units)\n",
    "\n",
    "    # Layer di output\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "    print('Dense', 1)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=15, verbose=1)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=120, batch_size=32, callbacks=[early_stop])\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(np.int32)  # Converte probabilità in valori binari\n",
    "\n",
    "    # Usa l'accuratezza di validazione come metrica da ottimizzare\n",
    "    precision = precision_score(y_test, y_pred_binary)\n",
    "    recall = recall_score(y_test, y_pred_binary)\n",
    "\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    return precision + precision + recall\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Numero di trials: \", len(study.trials))\n",
    "print(\"Miglior trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
